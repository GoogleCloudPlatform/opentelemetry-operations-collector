# Copyright 2020, Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This config supports Apache, DogStatsD (not curated), JVM, and MySQL
# metrics.
#
# Where necessary, you can configure environment-specific details as
# specified in the receivers section below. You can remove the pipelines
# you don't need in the pipelines section at the bottom of this file.
#
# Note that application metrics will be reported as custom metrics by
# default. Curated metrics are explicitly prefixed with
# agent.googleapis.com in the relevant metricstransform processor.

receivers:
  # scrape system metrics at 1m interval
  hostmetrics:
    collection_interval: 1m
    scrapers:
      # commented out disk and process scrapers because:
      # 1. When sending scraped disk metrics into Google Cloud Monitoring, there is an error message "One or more TimeSeries could not be written: Points must be written in order. One or more of the points specified had an older start time than the most recent point"
      # 2. The process scraper produces an error of "no such file or directory" when readlink "/proc/2/exe", "/proc/3/exe", etc.
      cpu:
      # disk:
      filesystem:
      load:
      memory:
      network:
      paging:
      # process:     

  # https://github.com/Lusitaniae/apache_exporter
  prometheus_exec/apache:
    exec: ./prometheus_exporter/apache_exporter --telemetry.address=":{{port}}"
    port: 9117

  # https://github.com/prometheus/jmx_exporter
  prometheus_exec/jvm:
    # see prometheus_exporter_config/jvm_config.yaml for JMX configuration, notably the `jmxUrl` key
    exec: java -jar ./prometheus_exporter/jmx_exporter.jar {{port}} prometheus_exporter_config/jvm_config.yaml
    port: 9404

  # https://github.com/prometheus/mysqld_exporter
  prometheus_exec/mysql:
    # The --no-collect.global_variables flag reduces the amount of generated metrics. This can be removed to enable all (600+) MySQL metrics
    exec: ./prometheus_exporter/mysqld_exporter --web.listen-address=":{{port}}" --no-collect.global_variables
    port: 9104
    env:
      # DATA_SOURCE_NAME and its value are needed to connect to the MySQL server, alternatively you could use a .my.cnf configuration file
    # - name: DATA_SOURCE_NAME  
    #   value: username:password@(host:port)/db_name  # replace all values here with your MySQL server credentials

  # https://github.com/prometheus/statsd_exporter
  prometheus_exec/statsd:
    exec: ./prometheus_exporter/statsd_exporter
    port: 9102

  # scrape agent self-observability metrics
  prometheus/agent:
    config:
      scrape_configs:
      - job_name: 'otel-collector'
        scrape_interval: 1m
        static_configs:
        - targets: ['0.0.0.0:8888']

processors:
  # append resource information from GCE or EC2 metadata
  resourcedetection:
    detectors: [gce, ec2]

  # perform custom transformations that aren't supported by the metricstransform processor
  agentmetrics/system:
    # 1. converts up down sum types to gauges
    # 2. combines resource process metrics into metrics with processes as labels
    # 3. splits "disk.io" metrics into read & write metrics
    # 4. creates utilization metrics from usage metrics

  # filter out metrics not currently supported by cloud monitoring
  filter/system:
    metrics:
      exclude:
        match_type: strict
        metric_names:
          - system.filesystem.inodes.usage
          - system.network.dropped
          - system.paging.faults

  # convert from opentelemetry metric formats to cloud monitoring formats
  metricstransform/system:
    transforms:
      # system.cpu.time -> cpu/usage_time
      - metric_name: system.cpu.time
        action: update
        new_name: cpu/usage_time
        operations:
          # change data type from double -> int64
          - action: toggle_scalar_data_type
          # change label cpu -> cpu_number
          - action: update_label
            label: cpu
            new_label: cpu_number
          # change label state -> cpu_state
          - action: update_label
            label: state
            new_label: cpu_state
          # take mean over cpu_number dimension, retaining only cpu_state
          - action: aggregate_labels
            label_set: [ cpu_state ]
            aggregation_type: mean
      # system.cpu.utilization -> cpu/utilization
      - metric_name: system.cpu.utilization
        action: update
        new_name: cpu/utilization
        operations:
          # change label cpu -> cpu_number
          - action: update_label
            label: cpu
            new_label: cpu_number
          # change label state -> cpu_state
          - action: update_label
            label: state
            new_label: cpu_state
          # take mean over cpu_number dimension, retaining only cpu_state
          - action: aggregate_labels
            label_set: [ cpu_state ]
            aggregation_type: mean
      # system.cpu.load_average.1m -> cpu/load_1m
      - metric_name: system.cpu.load_average.1m
        action: update
        new_name: cpu/load_1m
      # system.cpu.load_average.5m -> cpu/load_5m
      - metric_name: system.cpu.load_average.5m
        action: update
        new_name: cpu/load_5m
      # system.cpu.load_average.15m -> cpu/load_15m
      - metric_name: system.cpu.load_average.15m
        action: update
        new_name: cpu/load_15m
      # system.disk.read_io (as named after custom split logic) -> disk/read_bytes_count
      - metric_name: system.disk.read_io
        action: update
        new_name: disk/read_bytes_count
      # system.disk.write_io (as named after custom split logic) -> processes/write_bytes_count
      - metric_name: system.disk.write_io
        action: update
        new_name: disk/write_bytes_count
      # system.disk.operations -> disk/operation_count
      - metric_name: system.disk.operations
        action: update
        new_name: disk/operation_count
      # system.disk.io_time -> disk/io_time
      - metric_name: system.disk.io_time
        action: update
        new_name: disk/io_time
        operations:
          # change data type from double -> int64
          - action: toggle_scalar_data_type
      # system.disk.operation_time -> disk/operation_time
      - metric_name: system.disk.operation_time
        action: update
        new_name: disk/operation_time
        operations:
          # change data type from double -> int64
          - action: toggle_scalar_data_type
      # system.disk.pending_operations -> disk/pending_operations
      - metric_name: system.disk.pending_operations
        action: update
        new_name: disk/pending_operations
        operations:
          # change data type from int64 -> double
          - action: toggle_scalar_data_type
      # system.disk.merged -> disk/merged_operations
      - metric_name: system.disk.merged
        action: update
        new_name: disk/merged_operations
      # system.filesystem.usage -> disk/bytes_used
      - metric_name: system.filesystem.usage
        action: update
        new_name: disk/bytes_used
        operations:
          # change data type from int64 -> double
          - action: toggle_scalar_data_type
          # take sum over mode, mountpoint & type dimensions, retaining only device & state
          - action: aggregate_labels
            label_set: [ device, state ]
            aggregation_type: sum
      # system.filesystem.utilization -> disk/percent_used
      - metric_name: system.filesystem.utilization
        action: update
        new_name: disk/percent_used
        operations:
          # take sum over mode, mountpoint & type dimensions, retaining only device & state
          - action: aggregate_labels
            label_set: [ device, state ]
            aggregation_type: sum
      # system.memory.usage -> memory/bytes_used
      - metric_name: system.memory.usage
        action: update
        new_name: memory/bytes_used
        operations:
          # change data type from int64 -> double
          - action: toggle_scalar_data_type
          # aggregate state label values: slab_reclaimable & slab_unreclaimable -> slab
          - action: aggregate_label_values
            label: state
            aggregated_values: [slab_reclaimable, slab_unreclaimable]
            new_value: slab
            aggregation_type: sum
      # system.memory.utilization -> memory/percent_used
      - metric_name: system.memory.utilization
        action: update
        new_name: memory/percent_used
        operations:
          # sum state label values: slab = slab_reclaimable + slab_unreclaimable
          - action: aggregate_label_values
            label: state
            aggregated_values: [slab_reclaimable, slab_unreclaimable]
            new_value: slab
            aggregation_type: sum
      # system.network.io -> interface/traffic
      - metric_name: system.network.io
        action: update
        new_name: interface/traffic
        operations:
          # change direction label values receive -> rx
          - action: update_label
            label: direction
            value_actions:
              # receive -> rx
              - value: receive
                new_value: rx
              # transmit -> tx
              - value: transmit
                new_value: tx
      # system.network.errors -> interface/errors
      - metric_name: system.network.errors
        action: update
        new_name: interface/errors
        operations:
          # change direction label values receive -> rx
          - action: update_label
            label: direction
            value_actions:
              # receive -> rx
              - value: receive
                new_value: rx
              # transmit -> tx
              - value: transmit
                new_value: tx
      # system.network.packets -> interface/packets
      - metric_name: system.network.packets
        action: update
        new_name: interface/packets
        operations:
          # change direction label values receive -> rx
          - action: update_label
            label: direction
            value_actions:
              # receive -> rx
              - value: receive
                new_value: rx
              # transmit -> tx
              - value: transmit
                new_value: tx
      # system.network.connections -> network/tcp_connections
      - metric_name: system.network.connections 
        action: update
        new_name: network/tcp_connections
        operations:
          # change data type from int64 -> double
          - action: toggle_scalar_data_type
          # WARN: if UDP connections are added to this metric in the OT Collector, the following operation will need to be revisited
          # delete single-valued protocol dimension ("tcp"), retaining only state
          - action: aggregate_labels
            label_set: [ state ]
            aggregation_type: sum
          # change label state -> tcp_state
          - action: update_label
            label: state
            new_label: tcp_state
      # system.paging.usage -> swap/bytes_used
      - metric_name: system.paging.usage
        action: update
        new_name: swap/bytes_used
        operations:
          # change data type from int64 -> double
          - action: toggle_scalar_data_type
      # system.paging.utilization -> swap/percent_used
      - metric_name: system.paging.utilization
        action: update
        new_name: swap/percent_used
      # system.paging.operations -> swap/io
      - metric_name: system.paging.operations
        action: update
        new_name: swap/io
        operations:
          # delete single-valued type dimension ("major"), retaining only direction
          - action: aggregate_labels
            label_set: [ direction ]
            aggregation_type: sum
      # process.cpu.time -> processes/cpu_time
      - metric_name: process.cpu.time
        action: update
        new_name: processes/cpu_time
        operations:
          # change data type from double -> int64
          - action: toggle_scalar_data_type
          # change label state -> user_or_syst
          - action: update_label
            label: state
            new_label: user_or_syst
            # change label value system -> syst  
            value_actions:
              - value: system
                new_value: syst
      # process.disk.read_io (as named after custom split logic) -> processes/disk/read_bytes_count
      - metric_name: process.disk.read_io
        action: update
        new_name: processes/disk/read_bytes_count
      # process.disk.write_io (as named after custom split logic) -> processes/disk/write_bytes_count
      - metric_name: process.disk.write_io
        action: update
        new_name: processes/disk/write_bytes_count
      # process.memory.physical_usage -> processes/rss_usage
      - metric_name: process.memory.physical_usage
        action: update
        new_name: processes/rss_usage
        operations:
          # change data type from int64 -> double
          - action: toggle_scalar_data_type
      # process.memory.virtual_usage -> processes/vm_usage
      - metric_name: process.memory.virtual_usage
        action: update
        new_name: processes/vm_usage
        operations:
          # change data type from int64 -> double
          - action: toggle_scalar_data_type

  # filter to include only apache metrics curated by cloud monitoring
  filter/apache:
    metrics:
      include:
        match_type: strict
        metric_names: 
          - apache_connections
          - apache_scoreboard
          - apache_sent_kilobytes_total
          - apache_workers
          - promhttp_metric_handler_requests_total

  # convert from prometheus exporter metric formats to cloud monitoring formats
  metricstransform/apache:
    transforms:
      # apache_connections -> apache/connections
      - metric_name: apache_connections
        action: update
        new_name: agent.googleapis.com/apache/connections
        operations:
          - action: aggregate_labels
            label_set: []
            aggregation_type: max
      # apache_scoreboard -> apache/scoreboard
      - metric_name: apache_scoreboard
        action: update
        new_name: agent.googleapis.com/apache/scoreboard
        operations:
          - action: update_label
            label: state
            value_actions:
              - value: dns
                new_value: dnslookup
              - value: idle
                new_value: waiting
              - value: open_slot
                new_value: open
              - value: read
                new_value: reading
              - value: reply
                new_value: sending
              - value: startup
                new_value: starting
              - value: graceful_stop
                new_value: finishing
      # apache_sent_kilobytes_total -> apache/traffic
      - metric_name: apache_sent_kilobytes_total
        action: update
        new_name: agent.googleapis.com/apache/traffic
        operations:
          - action: toggle_scalar_data_type
      # apache_workers -> apache/idle_workers
      - metric_name: apache_workers
        action: update
        new_name: agent.googleapis.com/apache/idle_workers
        operations:
          # WARN: this is a hack since the correct value is not necessarily max
          - action: aggregate_labels
            label_set: []
            aggregation_type: max
      # promhttp_metric_handler_requests_total -> apache/request_count
      - metric_name: promhttp_metric_handler_requests_total
        action: update
        new_name: agent.googleapis.com/apache/request_count
        operations:
         - action: aggregate_labels
           label_set: []
           aggregation_type: sum
         - action: toggle_scalar_data_type 

  # filter to include only jvm metrics curated by cloud monitoring
  filter/jvm:
    metrics:
      include:
        match_type: strict
        metric_names: 
          - java_lang_Memory_HeapMemoryUsage_committed
          - java_lang_Memory_HeapMemoryUsage_max
          - java_lang_Memory_HeapMemoryUsage_used
          - java_lang_Memory_NonHeapMemoryUsage_committed
          - java_lang_Memory_NonHeapMemoryUsage_max
          - java_lang_Memory_NonHeapMemoryUsage_used
          - java_lang_OperatingSystem_OpenFileDescriptorCount
          - java_lang_Threading_DaemonThreadCount
          - java_lang_Threading_ThreadCount

  # convert from prometheus exporter metric formats to cloud monitoring formats
  metricstransform/jvm:
    transforms:
      # TODO: consider changing the following six transforms to use action: combine
      # java_lang_Memory_HeapMemoryUsage_committed -> jvm/memory/usage{memory_type=heap,usage_kind=committed}
      - metric_name: java_lang_Memory_HeapMemoryUsage_committed
        action: update
        new_name: agent.googleapis.com/jvm/memory/usage
        operations:
          - action: add_label
            new_label: memory_type
            new_value: heap
          - action: add_label
            new_label: usage_kind
            new_value: committed
      # java_lang_Memory_HeapMemoryUsage_max -> jvm/memory/usage{memory_type=heap,usage_kind=max}
      - metric_name: java_lang_Memory_HeapMemoryUsage_max
        action: update
        new_name: agent.googleapis.com/jvm/memory/usage
        operations:
          - action: add_label
            new_label: memory_type
            new_value: heap
          - action: add_label
            new_label: usage_kind
            new_value: max
      # java_lang_Memory_HeapMemoryUsage_used -> jvm/memory/usage{memory_type=heap,usage_kind=used}
      - metric_name: java_lang_Memory_HeapMemoryUsage_used
        action: update
        new_name: agent.googleapis.com/jvm/memory/usage
        operations: 
          - action: add_label
            new_label: memory_type
            new_value: heap
          - action: add_label
            new_label: usage_kind
            new_value: used
      # java_lang_Memory_NonHeapMemoryUsage_committed -> jvm/memory/usage{memory_type=non_heap,usage_kind=committed}
      - metric_name: java_lang_Memory_NonHeapMemoryUsage_committed
        action: update
        new_name: agent.googleapis.com/jvm/memory/usage
        operations: 
          - action: add_label
            new_label: memory_type
            new_value: non_heap
          - action: add_label
            new_label: usage_kind
            new_value: committed
      # java_lang_Memory_NonHeapMemoryUsage_max -> jvm/memory/usage{memory_type=non_heap,usage_kind=max}
      - metric_name: java_lang_Memory_NonHeapMemoryUsage_max
        action: update
        new_name: agent.googleapis.com/jvm/memory/usage
        operations: 
          - action: add_label
            new_label: memory_type
            new_value: non_heap
          - action: add_label
            new_label: usage_kind
            new_value: max
      # java_lang_Memory_NonHeapMemoryUsage_used -> jvm/memory/usage{memory_type=non_heap,usage_kind=used}
      - metric_name: java_lang_Memory_NonHeapMemoryUsage_used
        action: update
        new_name: agent.googleapis.com/jvm/memory/usage
        operations: 
          - action: add_label
            new_label: memory_type
            new_value: non_heap
          - action: add_label
            new_label: usage_kind
            new_value: used
      # java_lang_OperatingSystem_OpenFileDescriptorCount -> jvm/os/open_files
      - metric_name: java_lang_OperatingSystem_OpenFileDescriptorCount
        action: update
        new_name: agent.googleapis.com/jvm/os/open_files
      # java_lang_Threading_DaemonThreadCount -> jvm/thread/num_daemon
      - metric_name: java_lang_Threading_DaemonThreadCount
        action: update
        new_name: agent.googleapis.com/jvm/thread/num_daemon
      # java_lang_Threading_ThreadCount -> jvm/thread/num_live
      - metric_name: java_lang_Threading_ThreadCount
        action: update
        new_name: agent.googleapis.com/jvm/thread/num_live

  # filter to include only mysql metrics curated by cloud monitoring
  filter/mysql:
    metrics:
      include:
        match_type: strict
        metric_names: 
          - mysql_global_status_commands_total
          - mysql_global_status_handlers_total
          - mysql_global_status_threads_connected

  # convert from prometheus exporter metric formats to cloud monitoring formats
  metricstransform/mysql:
    transforms:
      # mysql_global_status_commands_total -> mysql/command_count
      - metric_name: mysql_global_status_commands_total
        action: update
        new_name: agent.googleapis.com/mysql/command_count
        operations:
          - action: toggle_scalar_data_type
      # mysql_global_status_handlers_total -> mysql/handler_count
      - metric_name: mysql_global_status_handlers_total
        action: update
        new_name: agent.googleapis.com/mysql/handler_count
        operations:
          - action: toggle_scalar_data_type
          - action: update_label
            label: handler
            new_label: kind
      # mysql_global_status_threads_connected -> mysql/thread_count
      - metric_name: mysql_global_status_threads_connected
        action: update
        new_name: agent.googleapis.com/mysql/thread_count
        operations:
          - action: add_label
            new_label: kind
            new_value: connected

  # filter to include only agent metrics supported by cloud monitoring
  filter/agent:
    metrics:
      include:
        match_type: strict
        metric_names:
          - otelcol_process_uptime
          - otelcol_process_memory_rss
          - otelcol_grpc_io_client_completed_rpcs
          - otelcol_googlecloudmonitoring_point_count

  # convert from opentelemetry metric formats to cloud monitoring formats
  metricstransform/agent:
    transforms:
      # otelcol_process_uptime -> agent/uptime
      - metric_name: otelcol_process_uptime
        action: update
        new_name: agent/uptime
        operations:
          # change data type from double -> int64
          - action: toggle_scalar_data_type
          # add version label
          - action: add_label
            new_label: version
            new_value: $USERAGENT
      # otelcol_process_memory_rss -> agent/memory_usage
      - metric_name: otelcol_process_memory_rss
        action: update
        new_name: agent/memory_usage
      # otelcol_grpc_io_client_completed_rpcs -> agent/api_request_count
      - metric_name: otelcol_grpc_io_client_completed_rpcs
        action: update
        new_name: agent/api_request_count
        operations:
          # change data type from double -> int64
          - action: toggle_scalar_data_type
        # TODO: below is proposed new configuration for the metrics transform processor
          # ignore any non "google.monitoring" RPCs (note there won't be any other RPCs for now)
        # - action: select_label_values
        #   label: grpc_client_method
        #   value_regexp: ^google\.monitoring
          # change label grpc_client_status -> state
          - action: update_label
            label: grpc_client_status
            new_label: state
          # delete grpc_client_method dimension, retaining only state
          - action: aggregate_labels
            label_set: [ state ]
            aggregation_type: sum
      # otelcol_googlecloudmonitoring_point_count -> agent/monitoring/point_count
      - metric_name: otelcol_googlecloudmonitoring_point_count
        action: update
        new_name: agent/monitoring/point_count
        operations:
          # change data type from double -> int64
          - action: toggle_scalar_data_type

exporters:
  # export system metrics to cloud monitoring using the agent prefix
  stackdriver/system:
    user_agent: $USERAGENT
    metric:
      prefix: agent.googleapis.com/

  # export application metrics to cloud monitoring using the custom prefix
  stackdriver/custom:
    user_agent: $USERAGENT
    metric:
      prefix: custom.googleapis.com/

  # export self-reported metrics to cloud monitoring using the agent prefix
  stackdriver/agent:
    user_agent: $USERAGENT
    metric:
      prefix: agent.googleapis.com/

service:
  # remove any unwanted pipelines from this list if desired
  pipelines:
    # reports system metrics to cloud monitoring
    metrics/system:
      receivers: [hostmetrics]
      processors: [agentmetrics/system, filter/system, metricstransform/system, resourcedetection]
      exporters: [stackdriver/system]

    # reports apache metrics to cloud monitoring
    metrics/apache:
      receivers: [prometheus_exec/apache]
      processors: [filter/apache, metricstransform/apache, resourcedetection]
      exporters: [stackdriver/custom]

    # reports jvm metrics to cloud monitoring
    metrics/jvm:
      receivers: [prometheus_exec/jvm]
      processors: [filter/jvm, metricstransform/jvm, resourcedetection]
      exporters: [stackdriver/custom]

    # reports mysql metrics to cloud monitoring
    metrics/mysql:
      receivers: [prometheus_exec/mysql]
      processors: [filter/mysql, metricstransform/mysql, resourcedetection]
      exporters: [stackdriver/custom]

    # reports statsd metrics to cloud monitoring
    metrics/statsd:
      receivers: [prometheus_exec/statsd]
      processors: [resourcedetection]
      exporters: [stackdriver/custom]

    # reports agent self-observability metrics to cloud monitoring
    metrics/agent:
      receivers: [prometheus/agent]
      processors: [filter/agent, metricstransform/agent, resourcedetection]
      exporters: [stackdriver/agent]
